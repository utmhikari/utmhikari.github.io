---
title: 【极客日常】用Coze简单开发一个Agent
date: 2025/08/10 14:24:15
categories:
- 极客日常
tags:
- coze
- LLM
- python
- Agent
- AI
---

近来AI大模型发展迅猛，不论是工业界还是生活界都纷纷开始进军AI，了解基于LLM的问答Agent需要如何开发。为了跟风，笔者也粗浅了解了下问答Agent开发的一些基础知识，简单开发了一个主要关注Python问答的Agent，挂在了自己的微信公众号上。

要开发一个问答Agent也很简单，重要的是得清楚一些本质：

<!-- more -->

- 问答Agent可以看作是一个函数：`func(userInput string) (chatOutput string)`。
- 函数中间的处理过程可以由纯自然语言描述（Prompt As ByteCode），也可以抽象成结构化的图形式（Compose Graph）。图节点里面可以干任何事情，不管是调用其它大模型、外部接口（MCP）甚至是调用外部Agent都是可以的。
- 要让chatOutput质量更好，兜底还是要产出更多的中间数据，让chatOutput能够充分理解整合上下文。中间数据可以自产自销（ReAct），先自己深入拆解问题，再每个各个击破，最后自己再整合。

之后就可以开始开发了。笔者采用Coze平台开发，进到项目里面创建一个Agent就可以动手了。里面有几个主要栏目：

- 人设与回复逻辑（Main Prompt）：本质上就是让你用自然语言描述问答Agent职责是什么，工作主流程是什么，对问答Agent做基本约束。
- 模型：用于理解自然语言并吐出回复，有新选新，这样回复的内容能和咱们的预期更加一致。如果要快速回答就谨慎选择深度推理。
- 插件：可以理解成外部接口，直接查外部资料，获取结构化的数据
- 工作流：用图描述的自然语言输入输出，配合了个低代码编辑器，玩过UE4/UE5的同学都不会陌生。如果偷懒的话，其实在Main Prompt里，强行让Agent用你的工作流执行工作主流程就行。
- 知识：可以用来约束Agent在特定问题条件下获取到的知识，防止知识污染。
- 记忆：如果把Agent当做一个后台服务的话，这个模块提供了数据持久化以及单次对话中缓存上下文变量的能力。
- 对话体验：主要优化Agent回答的舒适度，提供更多情绪价值。

结合这些模块之后，开发一个简单的Agent也不难。Coze里面有自带预览调试，如果专业一点的话也有Prompt评测系统用来管理变更质量（评测的话也是用大模型+Prompt直接做理解打分，非常方便）。发布的话，Coze也支持自己平台、豆包，甚至是微信公众号的分发渠道。笔者开发的Python问答Agent在Coze平台可以通过[这个链接](https://www.coze.cn/s/djjqbf7tuPo/)访问，有兴趣的同学可以和TA唠唠嗑。
