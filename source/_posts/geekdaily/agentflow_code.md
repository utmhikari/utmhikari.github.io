---
title: ã€æå®¢æ—¥å¸¸ã€‘æ™ºèƒ½åŒ–å·¥ç¨‹AgentFlowä»£ç å®ç°åˆ†æ
date: 2025/12/07 13:30:22
categories:
- æå®¢æ—¥å¸¸
tags:
- AgentFlow
- LLM
- AI
- å¼ºåŒ–å­¦ä¹ 
- æºç åˆ†æ
---

è¿‘æœŸç¬”è€…å› ä¸ºå‚ä¸LLMå¢å¼ºé¡¹ç›®æ”»åšï¼Œå¯¹LLMå·¥ç¨‹ç›¸å…³çš„æŠ€æœ¯ä¹Ÿå¸Œæœ›æœ‰ä¸€å®šçš„äº†è§£ï¼Œå› æ­¤å¸Œæœ›å€Ÿè¿™ä¸ªæœºä¼šï¼Œè¯»ä¸€äº›æ–‡ç« å……ç”µï¼Œçœ‹çœ‹ç›®å‰LLMæ™ºèƒ½åŒ–å·¥ç¨‹çš„ä¸€äº›ç ”ç©¶è¶‹åŠ¿ã€‚åœ¨é˜…è¯»äº†å‡ ç¯‡æ–‡ç« ä¹‹åï¼Œæœ€ç»ˆè¯»è€…é€‰å®š[AgentFlow](https://agentflow.stanford.edu/)è¿™ä¸ªé¡¹ç›®åšä»£ç å®ç°åˆ†æã€‚ç”±äºç¬”è€…åœ¨ç®—æ³•æ–¹é¢çš„æ¶‰çŒå®åœ¨ä¸æ·±ï¼Œæ‰€ä»¥æœ¬æ–‡åªæ˜¯æŠ›ç –å¼•ç‰ï¼Œé˜è¿°ä¸Šæœ‰ä»€ä¹ˆä¸ä¸“ä¸šä¸ä¸¥è°¨çš„åœ°æ–¹ï¼Œä¹Ÿè¾›è‹¦å¤§å®¶æŒ‡æ­£ã€‚

AgentFlowä¸»è¦è§£å†³ç°æœ‰LLMåœ¨è¿›è¡Œå·¥å…·å¢å¼ºæ¨ç†æ—¶æœ‰å¯æ‰©å±•å’Œæ³›åŒ–èƒ½åŠ›å·®çš„é—®é¢˜ï¼Œç®€å•æ¥è¯´å°±æ˜¯åœ¨çº¿LLM-AgentæœåŠ¡ç¼ºä¹åœ¨ç”Ÿäº§ç¯å¢ƒä¸­RLï¼ˆå¼ºåŒ–å­¦ä¹ ï¼‰çš„æ‰‹æ®µã€‚æ‰€ä»¥AgentFlowæå‡ºäº†ä»¥ä¸‹çš„è§£å†³æ–¹æ¡ˆï¼Œä¸€æ˜¯ä¸€å¥—åŠ¨æ€è®­ç»ƒPlannerçš„ç¼–æ’ï¼Œå¦å¤–ä¸€ä¸ªæ˜¯ä¸€å¥—å¥–åŠ±ç›®æ ‡è®­ç»ƒç®—æ³•Flow-GRPOã€‚æºç å¯ä»¥é€šè¿‡[è¿™ä¸ªGitHub](https://github.com/lupantech/AgentFlow)æ¥ä¸‹è½½ï¼Œè·‘äº†ä¸€ç•ªçœ‹Agentç¼–æ’çš„å®ç°æ¯”è¾ƒå®Œæ•´ï¼Œä½†åœ¨çº¿æœåŠ¡è·Ÿè®­ç»ƒçš„éƒ¨ç½²æ‰§è¡Œä¼šæ¯”è¾ƒéš¾æï¼Œæ‰€ä»¥æœ¬æ–‡æ›´å€¾å‘äºå¯¹Agentç¼–æ’åšè¯¦ç»†é˜è¿°ã€‚

Agentç¼–æ’åŒ…å«Plannerã€Executorã€Verifierè·ŸGeneratorå››ä¸ªè§’è‰²ï¼ŒPlannerä¼šä¸æ–­Rolloutåˆ¤æ–­ä¸‹ä¸€æ­¥è¦åšä»€ä¹ˆï¼ŒExecutoræ‰§è¡ŒToolCallï¼ŒVerifieråˆ¤æ–­å½“å‰é—®é¢˜æ˜¯å¦è§£å†³ï¼ŒGeneratorè´Ÿè´£æ•´åˆOutputã€‚æ•´ä¸ªæ ¸å¿ƒä»£ç é›†ä¸­åœ¨Solver.solveï¼Œé•¿è¿™ä¸ªæ ·å­ï¼š

<!-- more -->

```python
class Solver:
    def solve(self, question: str, image_path: Optional[str] = None):
        # Update cache directory for the executor
        self.executor.set_query_cache_dir(self.root_cache_dir)

        # Initialize json_data with basic problem information
        json_data = {
            "query": question,
            "image": image_path
        }

        # Generate base response if requested
        if 'base' in self.output_types:
            base_response = self.planner.generate_base_response(question, image_path, self.max_tokens)
            json_data["base_response"] = base_response

        # If only base response is needed, save and return
        if set(self.output_types) == {'base'}:
            return json_data
    
        # Continue with query analysis and tool execution if final or direct responses are needed
        if {'final', 'direct'} & set(self.output_types):
            # [1] Analyze query
            query_start_time = time.time()
            query_analysis = self.planner.analyze_query(question, image_path)
            json_data["query_analysis"] = query_analysis

            # Main execution loop
            step_count = 0
            action_times = []
            while step_count < self.max_steps and (time.time() - query_start_time) < self.max_time:
                step_count += 1
                step_start_time = time.time()

                # [2] Generate next step
                local_start_time = time.time()
                next_step = self.planner.generate_next_step(
                    question, 
                    image_path, 
                    query_analysis, 
                    self.memory, 
                    step_count, 
                    self.max_steps,
                    json_data
                )
                context, sub_goal, tool_name = self.planner.extract_context_subgoal_and_tool(next_step)

                if tool_name is None or tool_name not in self.planner.available_tools:
                    print(f"\n==> ğŸš« Error: Tool '{tool_name}' is not available or not found.")
                    command = "No command was generated because the tool was not found."
                    result = "No result was generated because the tool was not found."

                else:
                    # [3] Generate the tool command
                    local_start_time = time.time()
                    tool_command = self.executor.generate_tool_command(
                        question, 
                        image_path, 
                        context, 
                        sub_goal, 
                        tool_name, 
                        self.planner.toolbox_metadata[tool_name],
                        step_count,
                        json_data
                    )
                    analysis, explanation, command = self.executor.extract_explanation_and_command(tool_command)
                    
                    # [4] Execute the tool command
                    local_start_time = time.time()
                    result = self.executor.execute_tool_command(tool_name, command)
                    result = make_json_serializable_truncated(result) # Convert to JSON serializable format
                    json_data[f"tool_result_{step_count}"] = result
                
                # Track execution time for the current step
                execution_time_step = round(time.time() - step_start_time, 2)
                action_times.append(execution_time_step)

                # Update memory
                self.memory.add_action(step_count, tool_name, sub_goal, command, result)
                memory_actions = self.memory.get_actions()

                # [5] Verify memory (context verification)
                local_start_time = time.time()
                stop_verification = self.planner.verificate_context(
                    question, 
                    image_path, 
                    query_analysis, 
                    self.memory,
                    step_count,
                    json_data
                )
                context_verification, conclusion = self.planner.extract_conclusion(stop_verification)
                
                # Break the loop if the context is verified
                if conclusion == 'STOP':
                    break

            # Add memory and statistics to json_data
            json_data.update({
                "memory": memory_actions,
                "step_count": step_count,
                "execution_time": round(time.time() - query_start_time, 2),
            })

            # Generate final output if requested
            if 'final' in self.output_types:
                final_output = self.planner.generate_final_output(question, image_path, self.memory)
                json_data["final_output"] = final_output
                print(f"\n==> ğŸ™ Detailed Solution:\n\n{final_output}")

            # Generate direct output if requested
            if 'direct' in self.output_types:
                direct_output = self.planner.generate_direct_output(question, image_path, self.memory)
                json_data["direct_output"] = direct_output
                print(f"\n==> ğŸ™ Final Answer:\n\n{direct_output}")

            print(f"\n[Total Time]: {round(time.time() - query_start_time, 2)}s")
            print(f"\n==> âœ… Query Solved!")

        return json_data
```

è¯¦ç»†æ¥è®²æ˜¯è¿™æ ·ä¸€ä¸ªæµç¨‹ï¼š


- Analyze Query
    - Inputsï¼šQuestion & Tools -> Inject Into Prompts
    - Outputs: Query Analysis -> Brief & Concise
- Main Execution Loop
    - Planner.generate_next_step
        - Inputs: Question, Query Analysis, Memory & StepCount -> Inject Into Prompts
        - Outputs: NextStep -> Justification, Context, SubGoal & ToolName
    - Planner.extract_subgoal_and_tool -> JSON or REGEX
        - Inputs: NextStep
        - Outputs: Context, SubGoal & ToolName
    - CallTool if tool is active
        - Executor.generate_tool_command
            - Inputs: Question, Context, SubGoal & ToolMeta -> Inject Into Prompts
            - Outputs: ToolCommand
        - Executor.extract_explanation_and_command
            - Inputs: ToolCommand
            - Outputs: analysis, explanation & command
        - Executor.execute_tool_command
            - Inputs: ToolName & Command
            - Outputs: Result
    - Memory.add_action
        - Inputsï¼šStepCount, ToolName, SubGoal, Command, Result
    - Planner.verificate_context -> verify memory
        - Inputs: Question, Query Analysis, Memory, StepCount -> Inject Into Prompts
        - Outputs: Stop Verification -> Explanation + STOP/CONTINUE
    - Planner.extract_conclusion -> JSON or REGEX
        - Inputs: Stop Verification
        - Outputs: Context Verification (Explanation), Conclusion (STOP/CONTINUE)
    - Planner.generate_final_output/generate_direct_output
        - Inputs: Question, Memory -> Inject Into Prompts
        - Outputs: Chat Response

æœ¬è´¨ä¸Šè¿™å¥—æµç¨‹æ˜¯ä¸€ä¸ªå¤šå›åˆçš„MDPï¼ˆé©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹ï¼‰ï¼Œé€šè¿‡ä¸Šé¢4ä¸ªæ¨¡å—çš„åä½œï¼Œä¸æ–­é€¼è¿‘æœ€åˆç†çš„ç­”æ¡ˆã€‚ä½†ä»…ä»…æœ‰è¿™ä¸ªæ¡†æ¶è¿˜æ˜¯ä¸å¤Ÿçš„ï¼Œçº¯Rollouté€¼è¿‘çš„æ•ˆæœç†è®ºä¸Šè‚¯å®šæ²¡æœ‰ç»è¿‡è®­ç»ƒä¹‹åçš„å¥½ã€‚æ‰€ä»¥paperé‡Œé‡‡ç”¨Flow-GRPOè¿™å¥—ä½“ç³»æä¾›ç”Ÿäº§ç¯å¢ƒè®­ç»ƒèƒ½åŠ›ï¼Œæœ‰ä¸¤ä¸ªå…³é”®ç‚¹ï¼š

- QAå¥–åŠ±ï¼šå•æ¬¡QAå¥–åŠ±ä¼šå¹¿æ’­åˆ°æ¯ä¸ªstepï¼Œæœ€ç»ˆç»“æœå½±å“æ¯ä¸ªstepçš„å†³ç­–å¥–åŠ±ï¼›
- Group-Normalized-Advantagesï¼ˆç»„å½’ä¸€åŒ–ä¼˜åŠ¿ï¼‰ï¼šåœ¨æ¯ä¸ªè®­ç»ƒæ‰¹æ¬¡ä¸­ï¼Œç®—æ³•å¯¹åŒä¸€æ‰¹æ¬¡ï¼ˆå¹¶è¡Œrolloutsï¼‰æ‰€æœ‰è½¨è¿¹çš„ä¼˜åŠ¿å‡½æ•°åšå½’ä¸€åŒ–ï¼Œç¡®ä¿ä¼˜åŒ–æ¢¯åº¦åˆç†ï¼Œæœ¬è´¨ä¹Ÿç¬¦åˆ[GRPO](https://zhuanlan.zhihu.com/p/21046265072)çš„æ€è·¯ã€‚

è¦è¯¦ç»†äº†è§£AgentFlowè¿™å¥—GRPOå®ç°çš„è¯ï¼Œå¯ä»¥çœ‹[è¿™ä¸ª](https://zhuanlan.zhihu.com/p/1968984541726245379)ä»¥åŠ[å¦ä¸€ä¸ª](https://zhuanlan.zhihu.com/p/1960844370321347350)çŸ¥ä¹æ–‡ç« ï¼Œæ­¤å¤„ä¸å†èµ˜è¿°ã€‚ä»£ç æ–¹é¢çš„è¯ï¼Œç›®å‰ç¬”è€…æ²¡æœ‰è·‘é€šï¼Œä¹Ÿæœ‰å¯èƒ½éœ€è¦å€ŸåŠ©verlã€cudaä¹‹ç±»ç¯å¢ƒæ‰å¯ä»¥æŠŠæ•´ä¸ªè®­ç»ƒéªŒè¯è·‘èµ·æ¥ã€‚ä»å·²æœ‰ä¿¡æ¯æ¥çœ‹ï¼Œä¹Ÿè®¸è®­ç»ƒé€»è¾‘èµ°åˆ°äº†ä¸‹é¢çš„ä»£ç ï¼Œé€šè¿‡training_rollout_asyncå’Œ_solve_and_evaluateä¿è¯è®­ç»ƒé›†çš„Rolloutå’Œè¯„æµ‹å¯å¹¶å‘è¿›è¡Œï¼Œç„¶åäº§å‡ºä¸€æ‰¹rollout_dataï¼Œä½†rollout_dataçš„æ¶ˆè´¹é€»è¾‘ç›®å‰è¿˜ä¸æ˜ç¡®ã€‚å…·ä½“çš„è¯ï¼Œå¯ä»¥å‚è€ƒç›®å‰rolloutçš„é€»è¾‘ï¼š

```python
class Rollout(LitAgent):
    async def _solve_and_evaluate(self, rollout: AgentFlowRollout, task: Any, step_n: int, val: bool = False):
        """A helper function to run the agent, parse the result, and evaluate it."""
        result = {}
        try:
            output_format = "When ready, output the final answer enclosed in <answer> and </answer> tags. Do not generate any content after the </answer> tag."
            prompt = task["question"] + " " + output_format
            # prompt = task["question"]
            result = rollout.solve(question=prompt)
            
            # Safely check for and extract the final answer
            if "direct_output" in result and result["direct_output"]:
                final_output = result["direct_output"]
                all_matches = re.findall(r"<answer>(.*?)</answer>", final_output, re.DOTALL)
                if all_matches:
                    answer = all_matches[-1].strip()
                else:
                    answer = final_output
            else:
                print("Warning: Result has no direct_output or direct_output is empty.")
                answer = "None"
        except Exception as e:
            print(f"Failure during agent execution: {str(e)}. Defaulting to 'None'.")
            answer = "None"

        # Evaluate the answer against the ground truth
        reward_value = await eval(task["question"], str(task["result"]), answer, val)  # reward is tracked with the decorator
        print("answer: {} ground_truth: {} reward: {}".format(answer, task["result"], reward_value))

        idx = task.get("extra_info", {}).get("idx", "unknown_idx")

        rollout_data = {
            "step": task.get("step", ""), # TODO: check whether it can be solved
            "idx": idx,
            "id": task.get("id", ""),
            "prompt": task["question"],
            "model":rollout.llm_engine,
            "tools":self.tools,
            "groundtruth": task.get("extra_info", {}).get("groundtruth", task["result"]),
            "answer_extracted": answer,
            "reward": reward_value,
            "total_result":result,
            "timestamp": datetime.now().isoformat(),
        }

        data_id = str(uuid.uuid4())
        filename = f"rollout_{data_id}.json"

        save_dir = self.val_rollout_dir if val else self.train_rollout_dir

        # This function now uses the `step_n` passed as an argument.
        step_dir = os.path.join(save_dir, f"step_{step_n}")
        
        idx_dir = os.path.join(step_dir, f"idx_{idx}")
        os.makedirs(idx_dir, exist_ok=True)

        json_count = sum(
            len([f for f in files if f.endswith(".json")])
            for root, dirs, files in os.walk(idx_dir)
        )
        assert json_count < self.rollout_num, \
            f"Too many rollouts for idx {idx}: already {json_count} >= {self.rollout_num}"

        save_path = os.path.join(idx_dir, filename)

        with open(save_path, "w") as f:
            json.dump(rollout_data, f, indent=2)

        print(f"Rollout data saved to: {save_path}")

    async def training_rollout_async(self, task: Any, rollout_id: str, resources: NamedResources, val: bool = False) -> Any:
        await self._initialize_run_once(resources)

        if self.training_agent is None:
            print("Initializing training agent...")
            llm: LLM = resources.get("main_llm")
            self.training_agent = get_agent(
                llm.model,
                llm.endpoint,
                temperature=self.train_temperature,
                tools = self.tools,
                max_steps = self.max_steps,
                tool_engine = self.tool_engine,
                resources = resources,
                max_tokens = self.max_tokens,
                output_type= self.output_type,
                timeout= self.timeout,
            )
        
        # filelock to determine step_n ---
        lock = FileLock(self.train_lock_file, timeout=30)
        with lock:
            step_dirs = [d for d in os.listdir(self.train_rollout_dir) if d.startswith("step_")]
            step_nums = [int(d.replace("step_", "")) for d in step_dirs if d.replace("step_", "").isdigit()]
            
            current_step_n = 1
            if step_nums:
                current_step_n = max(step_nums)

            current_step_dir = os.path.join(self.train_rollout_dir, f"step_{current_step_n}")
            if os.path.exists(current_step_dir):
                num_items_in_step = len(os.listdir(current_step_dir))
                if num_items_in_step >= self.train_batch_size:
                    current_step_n += 1
            
            step_n = current_step_n

        await self._solve_and_evaluate(self.training_agent, task, step_n, val)
```
